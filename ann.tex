% !TEX root = main.tex
\chapter{Redes Neurais Artificiais}
\label{cha:ann}


A história de \textbf{Redes Neurais Artificiais} começou em 1943 com a fundação do modelo matemático proposto em \citep{mcculloch1943logical}, que em 1951 permitiu abordagens inspiradas na biologia cerebral e por aplicações em inteligência artificial \citep{kleene1951representation}, como no caso da criação de \textbf{Perceptron}\footnote{A menor unidade de processamento de uma rede neural, que pode fazer pequenos trabalhos de processamento por si só, mas pode cooperar com outros para alcançar uma convergência, mesmo para um trabalho enorme distribuído por um grande número de neurônios trabalhando em uma rede.} \citep{rosenblatt1958perceptron}, um algoritmo de classificação binária baseado no aprendizado supervisionado, um dos desenvolvimentos mais importantes no campo, publicado em 1958. Outro grande passo foi dado em 1967, quando foi publicado um trabalho sobre redes envolvendo múltiplas camadas \citep{ivakhnenko1967cybernetics}. A Seção \ref{sec:ann_perceptron} esclarecerá o funcionamento do Perceptron, então a Seção \ref{sec:ann_arch_and_prop} trará explicações sobre arquitetura e propriedades das redes neurais.

Alguns anos mais tarde, mais precisamente em 1972, dois grandes problemas foram identificados nos modelos de redes neurais então conhecidos: a incapacidade dos perceptrons básicos para processar operações de ``ou exclusivo'' (XOR) e a escassez de poder computacional exigido para se trabalhar com redes neurais de muitas camadas \citep{minsky1972perceptrons}. Estes problemas dificultaram muito para que houvesse qualquer avanço relevante nesta área durante vários anos, mas em 1975 foi proposto o \textbf{Backpropagation} \citep{werbos1975beyond}, um novo algoritmo que faria esta área de pesquisa continuar a ser interessante, uma vez que resolveria o problema de operação XOR e aceleraria o processamento em redes multi-camadas ajustando os pesos das camadas por meio de uma distribuição de erro. Uma explicação detalhada sobre Backpropagation será oferecida na Seção \ref{sec:ann_backpropagation}.

Considerando a alta demanda de poder computacional que tais modelos trouxeram consigo, pode-se dizer que muitos avanços na área foram conquistados nos anos seguintes, também por conta de trabalhos envolvendo paralelismo, por exemplo. \citep{rumelhart1986psychological}, de 1986. Em 1993 algumas melhorias foram alcançadas em redes neurais \citep{180705}; e, em 2010, o uso de Unidades de Processamento Gráfico na paralelização desta tarefa \citep{scherer2010evaluation} foi extremamente importante.

Também em 2006, um modelo de representações de alto nível foi proposto usando camadas sucessivas de variáveis latentes com máquinas Boltzmann \citep{hinton2006fast}. E, ainda mais recentemente, em 2013, foi introduzida uma rede suficientemente avançada para reconhecer conceitos avançados, como gatos em vídeos do YouTube \citep{le2013building} de maneira não supervisionada. Essas implementações de um grande número de camadas passaram a incluir em sua nomenclatura o termo ``Deep'' e, portanto, o termo \textbf{Deep Learning} tornou-se popular quando se refere a redes neurais artificiais profundas, também chamadas \textbf{Deep Neural Networks}.

Atualmente, existem inúmeras aplicações de Deep Learning para as mais diversas áreas de atividade, como neurociências \citep{Varatharajan2018}, IoT (Internet das Coisas) \citep{8396317}, segurança redes de computadores \citep{8291134}, reconhecimento facial \citep{8253595}, instrumentação \citep{8319916}, telecomunicações \citep{8359094}, imageamento médico \citep{8359121}, detecção de objetos \citep{8253582} tratamento de distúrbios da voz \citep{8337897}, mobilidade \citep{8344803} e tantos outros.



%   ----------------------
%   ----- Perceptron -----
%   ----------------------
\section{Perceptron}
\label{sec:ann_perceptron}

O \textit{Perceptron} é compreendido como a menor unidade neural capaz de realizar a tarefa de classificar dados linearmente separáveis, separando-os através de uma região fronteiriça denominada hiperplano\footnote{Hiperplano nada mais é do que a generalização de um plano para dimensões superiores; trata-se de uma forma geométrica com uma dimensão a menos que o hiperespaço, que é o caso que utiliza-se de todas as dimensões disponíveis}. O perceptron foi desenvolvido por Frank Rosenblatt \citep{rosenblatt1958perceptron}, enquanto trabalhava no \textit{Cornell Aeronautical Laboratory}, em um projeto financiado pelo \textit{Office of Naval Research}; e, diferentemente do que hoje se esperaria, teria sido originalmente planejado para ser uma máquina, não um programa de computador.

Em seu próprio trabalho original, Rosenblatt exibiu um esboço de como ele compreendia ser a organização do \textit{Perceptron}, bem como suas intraconexões, que envolviam componentes que ele chamou de Retina, Área de Projeção, Área de Associação e Respostas, como exibido na Figura \ref{fig:ann_perceptron_organization}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.85\textwidth]{figs/ann_perceptron_original_organization.pdf}
    \caption{Organização de um \textit{Perceptron}, segundo \citep{rosenblatt1958perceptron}.}
    \label{fig:ann_perceptron_organization}
\end{figure}

A Retina trata-se do primeiro componente dessa arquitetura; e é composta por unidades sensoriais com um comportamento que Rosenblatt assumiu como sendo \textit{tudo ou nada}, que pode ser mapeado binariamente. Os impulsos coletados pelos sensores da retina são enviados às chamadas \textit{células de associação}, que se localizam na \textit{área de projeção} (representada na Figura \ref{fig:ann_perceptron_organization} pela região circular $A_{I}$), mas essa região não está presente em todos os modelos de organização; no caso de não estar presente, a conexão é feita de forma direta entre os sensores da retina e a \textit{área de associação} ($A_{II}$).

As unidades da \textit{área de projeção} podem receber estímulos oriundos dos sensores da retina que resultem em excitação ou em inibição. O próprio conceito por detrás do que é comumente chamado de \textit{função de ativação} foi trazido neste mesmo trabalho, dado que, segundo Rosenblatt, as unidades $A$ emitem uma saída\footnote{Para os propósitos de seu modelo, Rosenblatt considerou a saída como sendo unitária, embora reconheça a possibilidade de ser utilizada outra abordagem.} sempre que a soma de todas as entradas da unidade em questão resultar em um valor igual ou superior ao limiar $\theta$ definido. As conexões feitas entre as unidades da área de projeção ($A_{I}$) e as da área de associação ($A_{II}$) foram tratadas como aleatórias, assim sendo, apesar de haver conexões entre unidades das diferentes áreas, tais conexões não necessariamente respeitarão uma específica distribuição; além disso, vale ressaltar que as características e os comportamentos das unidades em si, independentemente de a qual região pertençam, são os mesmos.

A respeito das \textit{respostas} ($R_{1}, \dots, R_{n}$), que são descritas como células ou grupos de células, seu comportamento é similar ao das unidades $A$; suas conexões, contudo, são um tanto diferentes, dado que, apesar de também serem feitas aleatoriamente, são altamente numerosas e são bidirecionais, permitindo uma comunicação diferenciadas com as unidades da área de associação ($A_{II}$), havendo para cada resposta $R$ um \textit{conjunto de origem}\footnote{Em uma tradução livre do que originalmente fora chamado de \textit{source-set}.}, ou seja, um conjunto de unidades $A_{II}$ que façam conexão com o a resposta em questão. A comunicação bidirecional permite a existência de \textit{feedback} da resposta para as unidades $A_{II}$ com as quais se comunica; e podem ser (a) excitatórias para todas as células de seu conjunto de origem ou (b) inibitórias para todas as células que não transmitam para a resposta em questão.

A partir de uma perspectiva mais contemporânea, o Perceptron passou a ser retratado de uma forma menos abstrata, utilizando funções algébricas explícitas e bem definidas, o que justifica, inclusive, a utilização de uma ilustração mais objetiva, assim como a representada pela Figura \ref{fig:ann_perceptron_new_organization}. Mas vale lembrar que esta nova versão é apenas uma forma diferente de representar artisticamente a mesma estrutura organizacional concebita por Rosenblatt. Não se trata, portanto, de uma real mudança da arquitetura original; apenas é feita uma ilustração que acompanhe uma interpretação sutilmente mais convidativa a partir de um olhar da perspectiva computacional.

\begin{figure}[H]
    \centering
    \includegraphics[width=1.00\textwidth]{figs/ann_perceptron_new_organization.pdf}
    \caption{Representação contemporânea da arquitetura de um \textit{Perceptron}.}
    \label{fig:ann_perceptron_new_organization}
\end{figure}


A partir da Figura \ref{fig:ann_perceptron_new_organization}, pode-se compreender que há um conjunto de entradas, $\bm{x}$, respectivamente ponderadas por um conjunto de pesos, $\bm{w}$, que, junto a um \textit{bias}, são somadas, então o resultado dessa soma é utilizado como entrada de uma \textit{função de ativação}, responsável por emitir o valor da saída, $\bm{y}$. O somatório (também chamado de \textit{campo local induzido} neste contexto) utiliza-se de uma combinação linear causada pela soma ponderada das entradas, além do \textit{bias}, o que resulta na separação de duas regiões por um \textit{hiperplano} \citep{haykin1999neural}, cuja definição matemática é dada por

\begin{equation}
    \sum_{i=1}^{N} w_{i} x_{i} + b = 0
    \label{eq:ann_perceptron_hyperplane}
    \hspace{0.1cm},
    \vspace{0.2cm}
\end{equation}

\noindent onde $N$ representa o número total de entradas\footnote{O trabalho original de Rosenblatt considerava um arranjo matricial em formato 20x20 em que cada unidade consistia em um sensor fotovoltaico que lia um sinal luminoso e emitia uma resposta de 0 ou 1 quando lia um cartão.} e, portanto, também de seus respectivos pesos para que seja possível efetuar as ponderações; e $b$ representa o \textit{bias}. A partir do resultado do campo local induzido, chega-se à \textit{função de ativação}, a respeito da qual será melhor discutido na seção seguinte.



%   ----- Funções de Ativação -----
\section{Funções de Ativação}
\label{sec:ann_activation_functions}

Um dos elementos mais importantes que compõem um \textit{Perceptron} é a \textit{função de ativação}, que funciona como um filtro que auxilia na tomada de decisões sobre o que fazer com o sinal resultante dos estímulos individuais que a ele chegam, sendo um dos responsáveis finais pela saída a ser obtida. Existem muitos tipos distintos de funções de ativação, não havendo uma função sequer que necessariamente seja melhor que todas as demais em todos os cenários possíveis, o que significa que sempre deverá ser analisado o cenário em questão, quais são os valores possíveis de entrada, quais as saídas desejadas e, também, qual o comportamento da função em toda a região intermediária, afinal, não são apenas os extremos que interferem no desempenho da rede; todos os elementos interferem, embora haja os que possam interferir em maior intensidade.

Uma das funções mais simples é a função \textit{identidade}, que permite quaisquer valores de entrada e saída, mas não se trata de uma das funções mais exploradas contemporaneamente; em vez disso, a função que assume tal posição de prestígio é a função ReLU, que será trazida ainda neste mesmo capítulo. Como o foco deste projeto não são as funções de ativação \textit{per se}, não será feita uma discussão aprofundada quanto a qualquer uma das funções, contudo, a fim de fornecer um material que possa ser utilizado pelo leitor para visualizar mais facilmente os efeitos de algumas funções de ativação, foram selecionadas algumas das mais comumente exploradas para que sejam aqui matematicamente definidas e tenham seu comportamento exibido graficamente para diferentes valores de \textit{bias}.

\pagebreak
\newpage

\begin{definition}[Função Identidade]
    Dada uma entrada $x$, a função Identidade pode ser definida como:

    \begin{equation}
        f(x) = x
        \vspace{0.2cm}
        \label{eq:ann_identity_function}
    \end{equation}

    A derivada da função identidade é:

    \begin{equation}
        f'(x) = 1
        \label{eq:ann_identity_function_dy}
    \end{equation}
    
\end{definition}

A Figura \ref{fig:ann_identity_function} exibe o comportamento da função identidade, bem com o de sua primeira derivada.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{figs/ann_identity_function.pdf}
    \caption{Comportamento da função identidade.}
    \label{fig:ann_identity_function}
\end{figure}


\linebreak
\newpage


\begin{definition}[Função Degrau Unitário]
    Dada uma entrada $x$, a função Degrau Unitário, também chamada de função Degrau Binário, pode ser definida como:

    \begin{equation}
        f(x) = u(x) = 
        \begin{cases}
            0, & \text{se $x < 0$}\\
            1, & \text{se $x \geq 0$}
        \end{cases}
        \vspace{0.2cm}
        \label{eq:ann_step_function}
    \end{equation}

    A derivada da função degrau unitário é:

    \begin{equation}
        f'(x) = u(x) = 
        \begin{cases}
            0, & \text{se $x \neq 0$}\\
            \text{?}, & \text{se $x = 0$}
        \end{cases}
        \vspace{0.2cm}
        \label{eq:ann_step_function_dy}
    \end{equation}
    
\end{definition}

A Figura \ref{fig:ann_step_function} exibe o comportamento da função degrau unitário (ou binário) e sua primeira derivada.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{figs/ann_unit_step_function.pdf}
    \caption{Comportamento da função degrau unitário.}
    \label{fig:ann_step_function}
\end{figure}


\linebreak
\newpage


\begin{definition}[Função Logística]
    Dada uma entrada $x$, a função Logística pode ser definida como:

    \begin{equation}
        f(x) = \sigma (x) = \dfrac{1}{1 + e^{-x}}
        \vspace{0.2cm}
        \label{eq:ann_logistic_function}
    \end{equation}

    A derivada da função logística é:

    \begin{equation}
        f'(x) = f(x)\ (1 - f(x))
        \label{eq:ann_logistic_function_dy}
    \end{equation}
    
\end{definition}

A Figura \ref{fig:ann_logistic_function} exibe o comportamento da função logística.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{figs/ann_logistic_function.pdf}

    \caption{Comportamento da função logística.}
    \label{fig:ann_logistic_function}
\end{figure}


\linebreak
\newpage


\begin{definition}[Função Tangente Hiperbólica]
    Dada uma entrada $x$, a função Tangente Hiperbólica pode ser definida como:

    \begin{equation}
        f(x) = \text{tanh}(x) = \dfrac{e^{x} - e^{-x}}{e^{x} + e^{-x}}
        \vspace{0.2cm}
        \label{eq:ann_tanh_function}
    \end{equation}

    A derivada da função tangente hiperbólica é:

    \begin{equation}
        f'(x) = 1 - (f(x))^{2}
        \label{eq:ann_tanh_function_dy}
    \end{equation}

\end{definition}

A Figura \ref{fig:ann_tanh_function} exibe o comportamento da função tangente hiperbólica e de sua derivada.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{figs/ann_tanh_function.pdf}

    \caption{Comportamento da função tangente hiperbólica.}
    \label{fig:ann_tanh_function}
\end{figure}


\linebreak
\newpage


\begin{definition}[Função Arco Tangente]
    Dada uma entrada $x$, a função Arco Tangente pode ser definida como:

    \begin{equation}
        f(x) = \text{tan}^{-1}(x)
        \vspace{0.2cm}
        \label{eq:ann_arctan_function}
    \end{equation}

    A derivada da função arco tangente é:

    \begin{equation}
        f'(x) = \dfrac{1}{x^{2} + 1}
        \label{eq:ann_arctan_function_dy}
    \end{equation}

\end{definition}

A Figura \ref{fig:ann_arctan_function} exibe o comportamento da função arco tangente com sua derivada.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{figs/ann_arctan_function.pdf}

    \caption{Comportamento da função arco tangente.}
    \label{fig:ann_arctan_function}
\end{figure}


\linebreak
\newpage


\begin{definition}[Função \textit{Rectified Linear Unit} (ReLU)]
    Dada uma entrada $x$, a função ReLU pode ser definida como:

    \begin{equation}
        f(x) =  
        \begin{cases}
            0, & \text{se $x < 0$}\\
            x, & \text{se $x \geq 0$}
        \end{cases}
        \vspace{0.2cm}
        \label{eq:ann_relu_function}
    \end{equation}

    A derivada da função ReLU é:

    \begin{equation}
        f'(x) = u(x) = 
        \begin{cases}
            0, & \text{se $x < 0$}\\
            1, & \text{se $x \geq 0$}
        \end{cases}
        \vspace{0.2cm}
        \label{eq:ann_relu_function_dy}
    \end{equation}

\end{definition}

A Figura \ref{fig:ann_relu_function} exibe o comportamento da função ReLU \citep{nair2010rectified} acompanhado de sua primeira derivada.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{figs/ann_relu_function.pdf}

    \caption{Comportamento da função ReLU.}
    \label{fig:ann_relu_function}
\end{figure}


\linebreak
\newpage


\begin{definition}[Função \textit{Leaky Rectified Linear Unit} (LReLU)]
    Dada uma entrada $x$, a função LReLU pode ser definida como:

    \begin{equation}
        f(x) = 
        \begin{cases}
            0.01 x, & \text{se $x < 0$}\\
            x, & \text{se $x \geq 0$}
        \end{cases}
        \vspace{0.2cm}
        \label{eq:ann_lrelu_function}
    \end{equation}

    A derivada da função LReLU é:

    \begin{equation}
        f'(x) = 
        \begin{cases}
            0.01, & \text{se $x < 0$}\\
            1, & \text{se $x \geq 0$}
        \end{cases}
        \vspace{0.2cm}
        \label{eq:ann_lrelu_function_dy}
    \end{equation}

\end{definition}

A Figura \ref{fig:ann_lrelu_function} exibe o comportamento da função LReLU \citep{maas2013rectifier} e sua primeira derivada.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{figs/ann_lrelu_function.pdf}

    \caption{Comportamento da função LReLU.}
    \label{fig:ann_lrelu_function}
\end{figure}


\linebreak
\newpage


\begin{definition}[Função \textit{Inverse Square Root Rectified Linear Unit} (ISRLU)]
    Dada uma entrada $x$, a função ISRLU pode ser definida como:

    \begin{equation}
        f(x) = 
        \begin{cases}
            \dfrac{x}{\sqrt{1 + \alpha x^{2}}}, & \text{se $x < 0$}\\
            x, & \text{se $x \geq 0$}
        \end{cases}
        \vspace{0.2cm}
        \label{eq:ann_isrlu_function}
    \end{equation}

    A derivada da função ISRLU é:

    \begin{equation}
        f'(x) = 
        \begin{cases}
            \left(\dfrac{1}{\sqrt{1 + \alpha x^{2}}}\right)^{3}, & \text{se $x < 0$}\\
            1, & \text{se $x \geq 0$}
        \end{cases}
        \vspace{0.2cm}
        \label{eq:ann_isrlu_function_dy}
    \end{equation}

\end{definition}

A Figura \ref{fig:ann_isrlu_function} exibe a função ISRLU \citep{carlile2017improving} junto à sua primeira derivada.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.65\textwidth]{figs/ann_isrlu_function.pdf}

    \caption{Comportamento da função ISRLU para $\alpha=1$ (em cima) e $\alpha=3$ (embaixo).}
    \label{fig:ann_isrlu_function}
\end{figure}


\linebreak
\newpage


%   ---------------------------------------
%   ----- Arquiteturas e Propriedades -----
%   ---------------------------------------
\section{Arquiteturas e Propriedades}
\label{sec:ann_arch_and_prop}

Uma Rede Neural Artificial (\textbf{ANN}, do inglês \textit{Artificial Neural Network}) é uma estrutura composta por neurônios interconectados distribuídos entre múltiplas camadas. Sua origem vem da ideia de imitar a função cerebral. Uma das características mais importantes das ANNs é a capacidade de aprender com ou sem supervisão (referências para análises comparativas), ou seja, as ANNs podem adotar uma abordagem de aprendizado supervisionado ou uma abordagem de aprendizado não supervisionada \citep{haykin1999neural}, dependendo da implementação do algoritmo de acordo com os objetivos do projeto.

\nomenclature{ANN}{\textit{Artificial Neural Network}}

Independentemente do tipo de rede neural artificial, os princípios básicos permanecem os mesmos; existem camadas de entrada, camadas ocultas e camadas de saída. Cada uma delas será explicada em mais detalhes posteriormente. Camadas ocultas são as principais responsáveis pelo aumento da demanda por poder de processamento, pois é onde residem os neurônios que realizam todo o processamento principal da rede.

Após uma primeira visão ingênua, talvez se imagine que, dado que os principais responsáveis pelo processamento são os neurônios localizados nas camadas intermediárias, o mais adequado seria aumentar sumariamente o número de neurônios para que isso produzisse um agressivo ganho de desempenho na atividade realizada pela rede; contudo, tal decisão seria, muito provavelmente, bastante equivocada e, sem dúvidas, nem um pouco parcimoniosa. Para se obter melhores resultados, portanto, é preciso estudar melhor sobre o funcionamento dos elementos que compõem toda a rede, além de explorar e analisar diferentes arquiteturas que podem ser mais propícias a responder melhor em certos ambientes específicos.

O impacto causado pelas redes neurais artificiais se intensificou drasticamente a partir da criação do Perceptron Multicamadas (\textbf{MLP}, \textit{Multilayer Perceptron}), que consiste em uma classe de redes de em que a informação é propagada apenas em uma direção, sendo enviada para a frente da rede. A estrutura de um MLP é composta por ao menos duas camadas intermediárias de neurônios, tal como pode ser visto pela Figura \ref{fig:ann_mlp}, o que permite que, em vez de ser projetado um único hiperplano para separar o hiperespaço de amostras a serem classificadas, passe a ser possível obter modelos bem mais flexíveis quanto a essas regiões de fronteira de separação.

\nomenclature{MLP}{\textit{Multilayer Perceptron}}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{figs/ann_mlp.pdf}
    \caption{Representação esquemática e genérica de um MLP.}
    \label{fig:ann_mlp}
\end{figure}

Já de longa data, os resultados obtidos levavam pesquisadores e desenvolvedores a acreditar que sua estrutura possuía características intrínsecas de alta capacidade de aproximação de modelos e, embora ainda não tivessem sido matematicamente provadas tais características, sua exploração por parte de diversos pesquisadores resultou em muitos importantes avanços na área. Ao fim da década de 1980 foram publicados trabalhos que efetuavam tal prova matemática em relação à sua capacidade de aproximação \citep{cybenko1989approximation, hornik1989multilayer}, embora tenha sido feita com base em funções sigmoidais. Pouco tempo depois foi publicado um trabalho que provava que, na verdade, essa capacidade de aproximação não era oriunda da função de ativação, mas, em vez disso, era advinda da própria estrutura do MLP, cujo fluxo de informação é direcionado para frente \citep{HORNIK1991251}.

Em 2017 foi provado que o Teorema da Aproximação Universal se aplica a redes profundas que utilizem funções de ativação do tipo ReLU quando respeitada a condição de que haja uma largura\footnote{Neste contexto, a largura da rede se refere apenas ao número de camadas intermediárias que a rede em questão possui, independentemente da quantidade de neurônios que cada uma possua ou da forma como os neurônios efetuem a comunicação entre camadas distintas.} mínima de $n+4$ camadas com o objetivo de se aproximar quaisquer funções que sejam Lebesgue integráveis \citep{royden1988real}. Finalmente, ainda no mesmo ano, foi provada essa capacidade de aproximação universal para qualquer função convexa contínua e, desta vez, necessitando apenas de $n+1$ camadas \citep{hanin2017universal}.




%   ---------------------------
%   ----- Backpropagation -----
%   ---------------------------
\section{Backpropagation}
\label{sec:ann_backpropagation}

O funcionamento iterativo do MLP depende da ocorrência de um treinamento que se dá majoritariamente por conta de um processo de otimização de custo, que se trata da redução do erro resultante da rede, composto pelos erros de cada um dos neurônios que compõem a rede. Para que os ajustes possam ser feitos de forma adequada em todos os neurônios, inclusive os que se localizam nas camadas mais distantes do fim da rede, é essencial que haja alguma maneira de levar a eles essa informação sobre o erro, assim cada neurônio poderá ter seu peso ajustado de forma independente dos demais, sempre com a missão de reduzir o erro final da rede, não especificamente seu próprio erro. Um dos algoritmos mais utilizados para realizar tal tarefa é conhecido como \textit{Backpropagation} \citep{Rumelhart1986, rumelhart1988parallel}.

Em seu livro \textit{Neural Networks: A Comprehensive Foundation} \citep{haykin1999neural}, Simon Haykin demonstra todo o funcionamento, passo a passo, da etapa de treinamento com o uso do algoritmo de \textit{Backpropagation}, com ilustrações e deduções matemáticas detalhadas, explicadas e comentadas. Haykin separa os casos em dois:

\begin{itemize}
    \item \textbf{Caso 1}: Neurônio de camada de saída
    \item \textbf{Caso 2}: Neurônio de camada oculta (intermediária)
\end{itemize}

Para o Caso 1, isoladamente, o cálculo do erro trata-se de um algoritmo supervisionado, dado que, para cada neurônio (de saída) $j$, existe a dependência de um valor desejado $d_{j}(n)$ para que o erro seja calculado. Assim, para os casos de neurônios da camada de saída, dada uma saída $y_{j}(n)$, o erro instantâneo $e_{j}(n)$ na iteração $n$ pode ser calculado por

\begin{equation}
    e_{j}(n) = d_{j}(n) - y_{j}(n)
    \label{eq:ann_instant_neuron_error}
    \hspace{0.1cm}.
    \vspace{0.2cm}
\end{equation}

Note que a Equação (\ref{eq:ann_instant_neuron_error}) independe de qualquer tratamento matemático rebuscado, dado que utiliza-se apenas do valor desejado (de referência) e do valor efetivamente obtido na saída para que o erro seja calculado. Contudo, para o Caso 2, o algoritmo calcula o \textit{gradiente descendente} \citep{cauchy1847methode} e propaga o erro no sentido oposto ao da transmissão da informação processada pela rede, passando por todas as camadas. O algoritmo considera inicialmente que a energia do erro de cada neurônio é igual a $\frac{1}{2}e_{j}^{2}(n)$ e interpreta que a soma de todos esses erros instantâneos resulta na energia total de erro $\mathcalboondox{E}(n)$, calculada como

\begin{equation}
    \mathcalboondox{E}(n) = \dfrac{1}{2}\sum_{j\ \in\ C}e_{j}^{2}(n)
    \label{eq:ann_total_error_energy}
    \vspace{0.2cm}
\end{equation}

\noindent onde $C$ é o conjunto de todos os neurônios da camada de saída. Caso seja feita a soma dos erros instantâneos de todos os neurônios da camada de saída e seja considerada a normalização de $n$ em relação a $N$, que é a o tamanho do conjunto de treinamento, a \textit{energia média do erro quadrático}, também interpretável neste contexto como \textit{erro quadrático médio} (\textbf{LMS}, \textit{Least Mean Square}), é definida como

\nomenclature{LMS}{\textit{Least Mean Square}}

\begin{equation}
    \mathcalboondox{E}_{\text{avg}}(n) = \dfrac{1}{N} \sum_{n=1}^{N} \mathcalboondox{E}(n)
    \label{eq:ann_avg_squared_error_energy}
    \vspace{0.2cm}
\end{equation}

A função $\mathcalboondox{E}_{\text{avg}}(n)$ é comumente utilizada como \textit{função custo} para se mensurar o desempenho do processo de aprendizagem correspondente a um determinado conjunto de treinamento; é essa a função a ser minimizada ao longo do processo de treinamento, e a cada iteração do treinamento são feitos ajustes sobre os parâmetros livres, como os pesos sinápticos e \textit{bias} da rede como consequência da otimização. O campo local induzido $\upsilon_{j}(n)$, que se trata do somatório observado na Figura \ref{fig:ann_perceptron_new_organization}, é definido como

\begin{equation}
    \upsilon_{j}(n) = \sum_{i=0}^{m} w_{ji}(n) y_{i}(n)
    \label{eq:ann_induced_local_field}
    \vspace{0.2cm}
\end{equation}

\noindent onde $w_{ij}(n)$ corresponde ao peso sináptico e $y_{i}(n)$ corresponde à saída do neurônio $i$, que nesta etapa é a entrada do campo local induzido $\upsilon_{j}(n)$ referente ao neurônio $j$, que se encontra na camada seguinte\footnote{É muito importante lembrar-se de que, em um contexto geral de MLP, as entradas de cada neurônio devem ser interpretadas como as saídas dos neurônios localizados na camada anterior.} àquela em que se encontra o neurônio $i$, e $m$ é o número de entradas advindas de neurônios da camada anterior, ou seja, excluindo-se o \textit{bias} na contagem. Após ser calculado o campo local induzido $\upsilon_{j}(n)$ do neurônio $j$, a \textit{função de ativação} $\phi_{j}(n)$ o recebe como entrada, o que produzirá a saída deste neurônio, $y_{j}(n)$, que pode ser matematicamente definida como

\begin{equation}
    y_{j}(n) = \varphi_{j}\left(\upsilon_{j}(n)\right)
    \label{eq:ann_neuron_output}
    \vspace{0.2cm}
\end{equation}

Segundo \citep{haykin1999neural}, o \textit{fator de sensibilidade} $\partial \mathcalboondox{E}(n) / \partial w_{ji}(n)$ pode ser representado como uma forma expandida da \textit{regra da cadeia} (do Cálculo)

\begin{equation}
    \dfrac{\partial \mathcalboondox{E}(n)}{\partial w_{ji}(n)} = \dfrac{\partial \mathcalboondox{E}(n)}{\partial e_{j}(n)}\ \dfrac{\partial e_{j}(n)}{\partial y_{j}(n)}\ \dfrac{\partial y_{j}(n)}{\partial \varphi_{j}(n)}\ \dfrac{\partial \varphi_{j}(n)}{\partial w_{ji}(n)}
    \label{eq:ann_gradient_chain_rule}
    \vspace{0.2cm}
\end{equation}

\noindent então, para que seja possível chegar ao valor, é necessário calcular cada uma das derivadas parciais envolvidas na Equação \ref{eq:ann_gradient_chain_rule}. A partir de derivadas parciais das Equações (\ref{eq:ann_total_error_energy}), (\ref{eq:ann_instant_neuron_error}), (\ref{eq:ann_neuron_output}) e (\ref{eq:ann_induced_local_field}), pode-se chegar aos valores de cada um dos termos da Equação (\ref{eq:ann_gradient_chain_rule}), o que leva a

\begin{equation}
    \setlength{\jot}{10pt}
    \begin{align}
    \dfrac{\partial \mathcalboondox{E}(n)}{\partial w_{ji}(n)} & = \left(e_{j}(n)\right)\ \left(-1\right)\ \left(\varphi_{j}'\left(\upsilon_{j}(n)\right)\right)\ \left(y_{i}(n)\right)\\
     & = -e_{j}(n)\ \varphi_{j}'\left(\upsilon_{j}(n)\right) y_{i}(n)
    \end{align}
    \label{eq:ann_backpropagation_partial}
    \hspace{0.1cm}.
    \vspace{0.2cm}
\end{equation}

Assim, utilizando-se a \textit{regra delta}, os ajustes de treinamento da rede podem, então, ser representados matematicamente por

\begin{equation}
    \Delta w_{ji}(n) = - \eta\ \dfrac{\partial \mathcalboondox{E}(n)}{\partial w_{ji}(n)}
    \label{eq:ann_delta_rule}
    \vspace{0.2cm}
\end{equation}

\noindent sendo $\eta$ a \textit{taxa de aprendizado} do algoritmo, um parâmetro de entrada do algoritmo a ser escolhido pelo projetista da rede, mas que deve ser cautelosamente escolhida. Taxas mais baixas provocarão alterações mais suaves e, consequentemente, mais lentas ao longo do processo de treinamento; ou outro lado, taxas mais elevadas, apesar de acelerarem o treinamento, resultam em perturbações mais abruptas ao longo do processo. Continuando, então, substituindo-se a Equação (\ref{eq:ann_backpropagation_partial}) em (\ref{eq:ann_delta_rule}), obtém-se

\begin{equation}
    \Delta w_{ji}(n) = -e_{j}(n)\ \varphi_{j}'\left(\upsilon_{j}(n)\right) y_{i}(n)
    \label{eq:ann_gradient_adjust_unfinished}
    \vspace{0.2cm}
\end{equation}

\noindent mas pode-se explorar o \textit{gradiente local} $\delta_{j}(n)$ para simplificar a equação, sendo que tal gradiente é dado por

\begin{equation}
    \setlength{\jot}{10pt}
    \begin{align}
    \delta_{j}(n)   & = - \dfrac{\partial \mathcalboondox{E}(n)}{\partial \upsilon_{j}(n)}\\
                    & = - \dfrac{\partial \mathcalboondox{E}(n)}{\partial e_{j}(n)}\ \dfrac{\partial e_{j}(n)}{\partial y_{j}(n)}\ \dfrac{\partial y_{j}(n)}{\partial \upsilon_{j}(n)}\\
                    & = e_{j}(n)\ \varphi_{j}'\left(\upsilon_{j}(n)\right)
    \end{align}
    \label{eq:ann_backpropagation_gradient}
    \hspace{0.1cm},
    \vspace{0.2cm}
\end{equation}

\noindent desta forma, pode-se reescrever a Equação (\ref{eq:ann_gradient_adjust_unfinished}) com o uso de (\ref{eq:ann_backpropagation_gradient}):

\begin{equation}
    \Delta w_{ji}(n) = \eta\ \delta_{j}(n)\ y_{i}(n)
    \label{eq:ann_gradient_adjust}
    \hspace{0.1cm},
    \vspace{0.2cm}
\end{equation}

\noindent ou seja, a \textit{correção dos pesos} $\Delta w_{ji}(n)$ é diretamente influenciada pela \textit{taxa de aprendizado} $\eta$, pelo \textit{gradiente local} $\delta_{j}(n)$ e pelo sinal de entrada do neurônio $j$, $y_{i}(n)$. 


%   -----------------------------------------------
%   ----- Aplicação aos Problemas Mencionados -----
%   -----------------------------------------------
\section{Aplicação aos Problemas Mencionados}
\label{sec:ann_application_mentioned_problem}

Os principais pontos sobre o uso das ANNs para este trabalho são: (1) o fato de que, assim como será exposto na Seção \ref{sec:gan_nn_as_generative_model}, ANNs possuem a capacidade de atuarem como algoritmos geradores, que, como tal, podem ser exploradas com o objetivo de reconstruir e, possivelmente, separar sinais; e, também, as GANs (Seção \ref{sec:gan_gan}) dependem de dois elementos adversariais com comportamentos como o de evoluírem quase que paralelamente, seguindo um processo de adaptação em que um dos elementos não se sobressaia demais em relação ao outro, o que faz com que as ANNs sejam altamente convenientes. Os avanços e ajustes feitos por parte de uma das redes tenderá a considerar os avanós e ajustes feitos pela outra rede, sem que para isso seja preciso inserir tais informações como parâmetros de entrada mutuamente dependentes.


%   ---------------------------
%   ----- Redes Profundas -----
%   ---------------------------
\section{Redes Profundas}
\label{sec:ann_deep_networks}

Apesar de praticamente todos os tópicos abordados até aqui serem relevantes tanto para \textit{redes neurais rasas}\footnote{Tradução livre do termo \textit{Shallow Neural Networks}, encontrado em alguns dos materiais de consulta para designar as redes não profundas, ou seja, as que possuem apenas uma única camada oculta.} quanto para \textit{redes neurais profundas}, este capítulo abordará mais especificamente as redes profundas, dado que serão elas a serem exploradas neste trabalho.

Os termos \textit{rasas} e \textit{profundas}, utilizados para caracterizar a ``profundidade'' da rede, ou seja, a quantidade de camadas ocultas (ou intermediárias) que as ANNs podem possuir em sua arquitetura, são apenas o que se conhece por \textit{Buzz-words}, termos não técnicos amplamente utilizados, neste caso, para designar redes neurais com, respectivamente, uma única camada oculta (\textit{rasas}) e duas ou mais camadas ocultas (\textit{profundas}). Não há um número exato que defina a quantidade de camadas ocultas necessárias para se chamar uma rede neural de \textit{profunda}, por outro lado, uma rede com apenas uma camada oculta é sempre interpretada como \textit{rasa}.



%   ----- Treinamento -----
\subsection{Treinamento}
\label{subsec:ann_training}

Assim que é criada a rede, ela ainda não está pronta para resolver qualquer problema que seja, pois ainda não se adequou a nada até então. O que faz com que a rede se comporte de um determinado modo é o seu treinamento, que realiza todos os ajustes necessários através de suas otimizações associadas ao longo do processo. Um dos exemplos mais típicos é o do algoritmo \textit{Backpropagation}, abordado na Seção \ref{sec:ann_backpropagation}. Em poucas palavras, o que o \textit{Backpropagation} faz é ajustar os parâmetros da rede de modo a torná-la capaz de aproximar regiões com geometrias mais convenientes. Um processo padrão realizado pela etapa de treinamento é composto por cinco tarefas bem definidas, que são:

\begin{enumerate}
    \item Inicialização dos \textit{pesos sinápticos} $w_{ji}(n)$, dos \textit{biases} $b_j(n)$ e, dependendo de como estiver estruturado o algoritmo, dos \textit{limiares} (\textit{Thresholds}) $\theta_{j}(n)$; \\
    \item Propagação para frente da rede, passando-se por todas as camadas intermediárias, até chegar ao valor obtido na saída da rede; \\
    \item Cálculo da \textit{função custo}, que auxilia na quantificação do quão bom foi o resultado obtido se comparado ao resultado almejado, ou seja, trata-se de uma forma de se constatar o erro da rede na iteração em questão; \\
    \item Propagação para trás da rede, atualizando os parâmetros $w_{ji}(n)$, $b_j(n)$ e $\theta_{j}(n)$ com o uso dos gradientes envolvidos no processo; \\
    \item Repetição das tarefas 2, 3 e 4 até que a função custo tenha sido suficientemente otimizada, porém, com o cuidado para que não ocorram problemas de \textit{Overfitting} ou \textit{Underfitting}.
\end{enumerate}

Além dessas tarefas, que são mais gerais e comuns, há diversas técnicas que almejam melhorar o algoritmo, seja reduzindo o custo computacional, seja atingindo valores melhores em suas métricas de qualidade. Uma técnica bastante eficaz quanto à redução do custo computacional é a de \textit{decaimento de taxa de aprendizado} (\textbf{LRD}, \textit{Learning Rate Decay}), que faz com que a \textit{taxa de aprendizado} seja alterada ao longo das iterações do algoritmo de treinamento, fazendo com que haja uma significativa redução no tempo demandado para que o processo de treinamento seja concluído; \textit{Adam}\footnote{Apenas como curiosidade, segundo os próprios autores declararam em sua publicação original \citep{kingma2014adam}, \textit{Adam} trata-se apenas de uma derivação de \textit{adaptive moment estimation}.} \citep{kingma2014adam} é um dos métodos mais utilizados e realiza uma otimização estocástica, sendo uma alternativa ao \textit{gradiente descendente estocástico} (\textbf{SGD}, \textit{Stochastic Gradient Descent}) \citep{robbins1951stochastic, kiefer1952stochastic}.

\nomenclature{LDR}{\textit{Learning Rate Decay}}
\nomenclature{SGD}{\textit{Stochastic Gradient Descent}}

Para se evitar \textit{Overfitting}, um método bastante explorado é o \textit{Dropout} \citep{srivastava2014dropout}, que aleatoriamente desabilita algumas das conexões interneurais da rede, mas apenas as dos neurônios das camada de entrada ou das camadas ocultas, afinal, se não houvesse alguma conexão com os neurônios da camada de saída, o cálculo do erro ficaria comprometido. Apesar de este algoritmo ser mais comumente utilizado com o objetivo de se diminuir os riscos de \textit{Overfitting}, pode-se interpretá-lo também como um otimizador, dado que ele reduz o custo computacional por conta da diminuição dos cálculos na etapa de treinamento em decorrência da desabilitação de algumas conexões da rede.







%   ----- Inicialização -----
\subsection{Inicialização}
\label{subsec:ann_initialization}

Apesar de ser possível iniciar a partir de diferentes configurações e, ainda assim, obter resultados altamente similares, ou até mesmo idênticos, isso não faz com que o processo de inicialização deva ser interpretado como de menor importância, pois erros podem, sim, ser cometidos nesta etapa; más escolhas podem não ser incócuas ao que se almeja quanto ao desempenho da rede e, principalmente, quanto aos seus objetivos finais.

A inicialização deste processo se dá pela escolha dos valores inicialmente assumidos para os \textit{pesos sinápticos} da rede, $w_{ji}(n)$, e para o \textit{limiar} $\theta_{j}$, que é utilizado para delimitar qual o mínimo valor necessário para que cada neurônio seja ativado, ou seja, para que o valor produzido por si seja levado em consideração pelo neurônio seguinte. Se forem utilizados valores iniciais demasiado elevados, há o risco de saturação, o que, devido a baixos valores de gradientes locais, pode resultar em uma considerável desaceleração do processo de treinamento. Por outro lado, a utilização de valores iniciais muito baixos, dependendo da função de ativação escolhida, pode fazer com que o algoritmo acabe trabalhando em uma região muito plana ao redor da superfície de erro.

Uma das possibilidades seria a de inicializar todos os pesos como sendo iguais a zero, porém essa pode não ser uma boa escolha, dado que isso faria com que a derivada em relação à \textit{função custo} fosse igual para todos os pesos, além do fato de que todas as camadas ocultas passariam a se comportar com base nos mesmos pesos, simetricamente, sendo esta uma realidade que seria preservada ao longo de todas as demais iterações, o que não tornaria o desempenho darede melhor do que seria se fosse simplesmente linear; ou seja, todo o sentido de se aceitar um enorme aumento do custo computacional para que fosse possível explorar aproximações mais complexas seria perdido.

Outra abordagem seria a de inicializar os valores por meio de sorteios aleatórios; possivelmente, respeitando uma dada \textit{função densidade de probabilidade} (\textbf{PDF}, \textit{Probability Density Function}), como uma distribuição Gaussiana ou uma distribuição uniforme. Aliás, uma das sugestões de inicialização feitas em \citep{haykin1999neural} é justamente a de se utilizar valores aleatórios de média zero e com uma variância apropriadamente selecionada para que os valores sorteados permitam que os resultados caiam em ambas as regiões da \textit{função de ativação} $\varphi_{j}(n)$, mas, preferencialmente, não em seus extremos.

Ainda assim, essas abordagens não são as mais convenientes para a maioria dos casos; e, dada a importância que fora constatada para a escolha apropriada de tais parâmetros, diversas técnicas bem mais rebuscadas foram desenvolvidas ao longo do tempo, tais como a \textit{He Initialization} \citep{he2015delving}, que utiliza-se de uma distribuição normal com média zero e desvio padrão dado por $\sqrt{\ 2\ / \left(N_{\text{\ in}} + N_{\text{\ out}}\right)}$, em que $N_{\text{\ in}}$ e $N_{\text{\ out}}$ são, respectivamente, o número de entradas e o número de saídas do neurônio; e \textit{Xavier} (ou \textit{Glorot}) \textit{Initialization} \citep{glorot2010understanding}, que segue uma distribuição normal com média zero e desvio padrão de $\sqrt{\ 1\ / \left(N_{\text{\ in}} + N_{\text{\ out}}\right)}$.